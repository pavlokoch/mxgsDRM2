#+TITLE:     DRM Notes
#+AUTHOR:    Brant Carlson
#+EMAIL:     brant.carlson@ift.uib.no
#+DESCRIPTION: describes detector response matrices and how they are generated
#+PROPERTY: eval no-export
#+OPTIONS: ^:{}

#+begin_src R :session s1 :results silent :exports none
source("../plotData.r");
#+end_src
  
* Introduction
** Primer on gamma-ray spectra
Data from particle detectors often needs a great deal of interpretation.  The spectrum measured by a solid state detector for a simple monoenergetic gamma-ray source like Cesium-137, shown in Figure \ref{fig:gammaRaySpect}, can be surprisingly complicated depending on the physics involved.  There are several identifiable features:
- Full-energy peak :: All of the energy of the incident photon is absorbed within the detector.
- Compton edge :: The incident photon Compton-scatters $\sim 180^\circ$ within the detector and escapes, the Compton electron deposits all its energy.
- One-escape peak :: The incident photon pair-produces in the detector, the positron annihilates in the detector, and one of the annihilation photons escapes the detector.
- Two-escape peak :: The incident photon pair-produces in the detector, the positron annihilates in the detector, and both of the annihilation photons escape the detector.
- Compton continuum :: The incident photon Compton-scatters at an angle less than $180^\circ$ and escapes, the Compton electron deposits some or all of its energy.
- Annihilation line :: The incident photon pair-produces somewhere outside the detector, the positron annihilates, and one of the annihilation photons is detected at full energy.
- Backscatter peak :: The incident photon Compton-scatters at a large angle outside the detector, then enters the detector and deposites all of its energy.
- X-ray lines :: The incident photon is photoelectrically absorbed outside the detector, ejecting an inner electron from the absorbing atom.  X-rays are emitted as remaining atomic electrons relax to fill the hole left by the ejected electron.  These x-rays can be detected.
There spectral features will not all appear depending on the energy of the incident photon.  In the case of MXGS, we expect a broad distribution of incident photon energies, meaning the measured spectrum will be a combination of some or all of these spectral features and their variation with energy convolved with the incident photon spectrum.  Perhaps suffice it to say this is a complicated problem made only more complicated by secondary processes like multiple scattering from non-detector mass, simultaneous energy deposition in multiple detector elements, and incident particles other than photons.  The whole problem must also be treated as a function of the direction from which the incident particle arrives.

#+CAPTION: Sample gamma-ray spectra, here from an Americium-Beryllium neutron source measured with a Germanium detector.  Various features are speculatively labeled, but many more are visible.
#+LABEL: fig:gammaRaySpect
[[./Am-Be-SourceSpectrum.jpg]]


** Spectrum determination
Given these complications, it is not generally possibly to determine the incident photon energy spectrum directly from the observed ``counts'' spectrum: the inverse problem cannot be solved.  The best that can be done is to solve the forward problem: predict the observed spectrum that would result from a given incident spectrum.  This can be done by simulating the response of the detector to particles with a variety of energies.  One can then combine these single-energy responses to determine the response of the detector to a spectrum of incident particles.

Typically, this is expressed as a detector response matrix (DRM).  Each row of the matrix represents the likelihood of observing a count at a particular energy as a function of the incident particle energy.  Alternatively, each column of the matrix represents the spectrum of counts observed for a particular incident photon energy.  The response of the detector to a given incident particle spectrum is the simply the matrix-vector product of the DRM with the incident particle spectrum.  This DRM is a function of the incident particle direction and of course particle type.  There are some subtleties, of course, described below, but this is the fundamental outline of the process.  The goal of this document is to simulate the detector response and determine the detector response matrices relevant to MXGS.

This goal breaks down into two main parts: detector simulation (Section \ref{sect:geant}), and detector response matrix construction (Section \ref{sect:processing}).  The technical details of the format and use of the resulting DRMs is described in Section \ref{sect:DRMuse}.


* Detector simulations
\label{sect:geant}
The simulation of the response of a particle detector is typically done as a Monte Carlo simulation of incident particles and how they might interact with the detector and its support structure.  These Monte Carlo simulations avoid the difficulties of accurately calculating the extremely complex integrals over incident particle position, possible interaction locations, possible interaction types, possible product particle geometry, possible product particle interactions, ... etc.  Such simulations have a long history in particle physics, and the tools used to construct them are quite mature.  The simulation tool used here is GEANT4, produced by CERN.  GEANT4 has been used for many years, and is used not only for detector simulations but also for particle accelerator design, radiotherapy, and medical physics, and is in general useful whenever energetic particle properties need to be simulated.  A GEANT4 simulation consists of several parts: the relevant laws of physics, the geometry of the simulation, generation of initial energetic particles, and data collection from the ``sensitive'' portions of the geometry (the detector), all tied together in a single program.  Technical details are given in the appendix.

** Relevant laws of physics
GEANT4 has an extremely flexible notion of ``the laws of physics.''  A simulation can be constructed that handles fictitious particles (the ``geantino'' for example), or uses any number of more realistic models of the familiar physics processes like Compton scattering.  Thankfully, GEANT4 includes many pre-defined ``physics lists'' that combine all of the physics GEANT4 knows about with various approximations suitable for various regimes.  Note that this is both good, as a user has some assurance that GEANT physics resembles real physics, and bad because GEANT often includes too much physics (e.g. photonuclear reactions, decay of the resulting nuclei, etc.) and therefore can run very slowly and give confusing results.  The simulations described in this document use the LHEP physics list, which includes GEANT4's treatment of:
- photon :: Compton scattering, pair production, and photoelectric effect, with extensions to include photonuclear reactions.
- lepton :: Multiple scattering, ionization, bremsstrahlung, and annihilation, for electrons, muons, and taus, and their antiparticles, with extension to include electro-nuclear interactions.
- hadron :: Relevant physics for charged hadrons (protons, neutrons, pions, kaons, deuterons, etc.), and assorted inelastic processes (e.g. pion absorption).
- decay :: All unstable particles decay with the relevant half-lives, probabilities, and product particles.


** Geometry
GEANT treats the geometry of parts of the simulation as simple solids (cubes, cylinders, tubes, spheres, etc.), combined with boolean operations (union, difference, intersection), the ``constructive solid geometry'' (CSG) approach.  This poses some difficulties, as the parts used for MXGS are designed with Creo Elements/Pro (Pro/Engineer), which uses a surface-based representation of parts, the ``boundary representation'' (BREP) approach.  While BREP is very useful (almost all CAD programs use BREP), there is no simple and efficient way to convert from BREP to CSG for use by GEANT.[fn:1]  As such, it was necessary to manually construct the geometry for GEANT4 from technical drawings of MXGS parts.  This has the decided disadvantage of requiring manual attention whenever the design changes.  Hopefully in the future this problem can be solved.

[fn:1] And not for lack of searching.  The best pathway from Pro/E to GEANT is to use Pro/E to produce a STEP file, convert the STEP file to a GDML file with FastRad (commercial), and read the GDML file with GEANT.  There are some non-commercial tools, but none that actually work.  I thought for a while that I could construct a chain from Pro/E to BRLCad to a general output format that I could write a program to convert to a format suitable for GEANT4 (BRLCad is also a CSG system), but I decided the problem was too complicated.

The geometry of the simulation is described by a series of files written in Geometry Description Markup Language (GDML, file extension .gdml), an XML-based format describing sizes, shapes, positions, and materials of elements of the simulation.  These files were constructed by hand over the series of several weeks.  If this seems like a waste of effort, discussions with the Fermi/GBM have repeatedly suggested that such detailed models of the spacecraft are necessary to ensure accurate simulation results: one small detail may not matter, but taken together, many small details can be quite important.  For example, the housing of a single BGO crystal is an aluminum box several millimeters thick but with thinner triangular-shaped regions milled away to reduce mass while retaining stiffness.  In reality, the thick regions of the box will block low-energy x-rays, while the thin regions will tend to allow such x-rays to pass.  As such, it is not correct to approximate the box as uniformly thick (too many low-energy x-rays blocked), uniformly thin (too few low-energy x-rays blocked), or uniformly intermediate (intermediate amount of x-rays blocked but with the wrong energy dependence).  Details like that may not be relevant in the end, but tending to include too much detail is prudent.

Each GDML file has the following sections
- define :: Definitions of constants, positions, and rotations.
- materials :: Definitions of elements and mixtures used to fill detector volumes.
- solids :: Definitions and combinations of shapes to define volumes.
- structure :: Definitions of volumes for simulation, which link solids to materials, and physical volumes, which link volumes to positions and rotations.
- setup :: Identifies the ``world volume'' for the GDML file, within which all simulation will take place.

GDML files can include each other, so the overall structure is as follows:
- columbus.gdml :: geometry of the Columbus module, includes asim.gdml and aces.gdml
- asim.gdml :: includes mmia.gdml and mxgs.gdml
- mxgs.gdml :: geometry of the outer structer of MXGS, includes codedMask.gdml and instrument.gdml
- instrument.gdml :: geometry of the shielding box, includes bgo.gdml and czt.gdml
- aces.gdml :: includes a crude model of the ACES instrument.
- codedMask.gdml :: generated by code in makeCM.py, describes the geometry of the tungsten shield in the coded mask.
- bgo.gdml :: geometry of the BGO detectors, including support structure.
- czt.gdml :: geometry of the CZT detectors, including support structure.

The drawings used to construct these files are current up to early 2012, with the exception of some of the new thermal and support structure.

The geometry used in the simulations is shown in Figure \ref{fig:geom}.

#+CAPTION: view of the geometry as used in GEANT.
#+LABEL: fig:geom
[[./freewrlsnap.png]]


** Primary particle generation
The primary particles to be simulated in this geometry are produced in a beam, incident from a given direction, centered on the detector.  The coordinate system used for the simulations has polar angle $\theta$ and azimuthal angle $\phi$, with $\theta=0^\circ$ corresponding to particles incident from directly below the space station (i.e. directly into MXGS).  $\theta=90^\circ$, $\phi=90^\circ$ points toward Columbus.

This raises several questions: what initial directions should be used, and how wide should the beam be made?  I don't have good answers yet, this section is unfinished.  The initial directions are chosen over a grid with resolution TBD.  

** Detector response simulation
Given physics, geometry, and a population of initial particles, the simulation can proceed.  As the simulation executes, a particle may be detected if it interacts within the sensitive volume of the detector (i.e. within the BGO bar or CZT wafer volumes).  Such an interaction will deposit a certain amount of energy in the detector, and the detectors are designed to produce a signal dependent on this energy deposition.  The conversion of energy deposition to signal strength is not straightforward, however.  In the case of BGO, the position of the energy deposition will determine the efficiency for scintillation photons to make their way to the photomultiplier tube, while in the CZT layer, the position of the energy deposition may fall on a boundary between multiple pixels.  For simplicity, we ignore the details of the physics connecting energy deposition to signal strength and simply record energy deposition.  In keeping with the framework described above of a single detector response matrix, we also sum all the energy deposition due to a single incident particle within the BGO and CZT layers.  In other words, if an incident high-energy photon pair produces in a CZT wafer, there will be multiple energy deposition events as the electron and positron propagate out of the CZT wafer, and possibly multiple energy deposition events in multiple the BGO bars as the electron, positron, and/or annihilation photons are absorbed.  In the simulation, such a process results in two numbers, the total energy deposited in the CZT wafers and the total energy deposited in the BGO bars.

As the simulation continues, many primary particles are simulated, producing many CZT and BGO energy deposition events.  These events are recorded and will be used to construct the detector response matrix.

** Simulation control
The structure described above is held together by the main simulation program, mxgsDRM.cc.  This program takes a variety of parameters determining the simulation to be executed:

#+begin_src sh :exports code
./mxgsDRM interactive(0|1) priPDGID(22,11,-11,...) \
    nPriPerE priStartDiskRad(m) priStartDiskRad0(m) \
    theta(deg) phi(deg) Emin(MeV) Emax(MeV) numEnergies \
    outEMin outEMax outNumE outputfileName  \
    ...rest of arguments written as comment to output file...
#+end_src

- interactive :: 0 for automatic run, 1 to be given a prompt to issue visualization and simulation commands via the GEANT4 command line.
- priPGDID :: PDG identified for the primary particle (22 for photons, 11 for electrons, -11 for positrons, etc.).
- nPriPerE :: number of primary particles per initial energy bin.
- priStartDiskRad :: maximum radius of beam of incident particles in meters, typically 0.6 m.
- priStartDiskRad0 :: minimum radius of beam of incident particles in meters, typically 0.0 m.
- theta :: polar angle from front of mxgs in degrees for all primary particles.
- phi :: azimuthal angle from side of mxgs in degrees for all primary particles.
- Emin, Emax :: limits of logarithmic initial energy grid in MeV.
- numEnergies :: number of initial energies to use in logarithmic initial energy grid.  For example, Emin = 0.1, Emax = 10, numEnergies = 3 will produce a grid with energies at 0.1, 1, and 1 MeV.
- outEMin, outEMax, outNumE :: limits and number of bins in histogram of energy deposition events in CZT and BGO layers.
- outputfileName :: name of output file to write histograms.

The main program constructs the physics and geometry of the simulation, then produces particles in a beam with the specified geometry.  nPriPerE primary particles are produced at each primary energy, and for each primary energy, two histograms counting energy deposition events (CZT and BGO) are accumulated and written to the output file.  Sample energy deposition histograms are shown in Figure \ref{fig:sampleHistograms}.

#+CAPTION: Sample energy deposition histograms for the BGO detector for a variety of primary energies.  Note that the energy deposition bins are uniform in logarithmic space.  Features like the full energy peak, one- and two-escape peaks, and the 500 keV annihilation line are clearly visible, but the Compton edge feature often seen in such spectra is difficult to identify due to multiple scattering in the complex geometry.
#+LABEL: fig:sampleHistograms
[[./sampleHists.pdf]]
		 
In order to achieve an accurate estimate of the detector response matrix, these histograms must each have many events, several thousand at a minimum.  As a beam of particles large enough to encompass MXGS, MMIA, ACES, and some of Columbus must be at least 1 m in radius, many particles will not reach the sensitive volume of the detector.  As such, around $10^6$ initial particles must be simulated at each primary energy (nPriPerE = $10^6$).  Given a grid of many initial energies, many millions of initial particles must be simulated in order to construct a single DRM.  As the DRM depends on the direction and identity of the initial particles, many DRMs must be created.  These simulations therefore take quite a large amount of computer time.  As a bare minimum, only running $5\times 10^5$ initial particles per primary energy at a grid of $\theta$ with $15^\circ$ resolution from $0^\circ$ to $90^\circ$ (7 $\theta$s) and $\phi$ with 30 degree resolution from $0^\circ$ to $180^\circ$ (7 $\phi$s) and a logarithmic grid in energy from 10 keV to 100 MeV with 41 points, just over $10^9$ primary particles must be simulated.  Test simulations on desktop computers run at an average rate of $\sim 500$ primary particles per second, so this minimal run corresponds to $\sim 20$ CPU-days of computer time.

These lengthy run times means running on a supercomputer is beneficial, and thankfully the structure of the simulations poses no obstacle to such simulations.  The supercomputer in question is fimm.bccs.uib.no, an 800-core cluster used for a variety of projects.  Running a simulation on such a supercomputer entails writing scripts to submit to the job queue.  Here these scripts are automatically generated by the program makePBS.py.  Changing the parameters in makePBS.py produces a set of .pbs files that can be submitted to the queue.  Once submitted, the scripts ensure that the output is placed in a directory of results, ready for processing once the jobs complete.  There are a lot of details here that I'm skipping over (copying the simulation to fimm, compiling GEANT on fimm, compiling the simulation on fimm, ensuring the environment is set correctly, submitting the scripts, etc.), but that describes the overall process.

  
* GEANT output processing
\label{sect:processing}
As described above, the output of the main simulation program is a file containing two sets of histograms, one set of BGO histograms and one set of CZT histograms.  Each histogram describes the number of energy deposition events per energy deposition bin as a function of deposited energy for a single primary energy.  These histograms need to be processed to become a true detector response matrix.

First, the histograms must be interpreted in the context of the simulation.  The $i$th entry of a histogram, $N_i$, refers to the number of times a total energy was deposited in the sensitive detector between $E^\mathrm{dep}_i$ and $E^\mathrm{dep}_{i+1}$ (i.e. $E^\mathrm{dep}_i$ are the bin boundaries of the histogram).  $N_i$ can be converted to an effective area by dividing by the total number of primary particles simulated and multiplying by the area over which those primaries were spread: $A^\mathrm{eff}_i = \frac{N_i}{n_\mathrm{pri}}*\pi*r_\mathrm{pri}^2$.  This effective area is a function of both the position and the size of the energy deposition bin in question, and typically the size of the energy bin is divided out: $\frac{dA^\mathrm{eff}(E^\mathrm{dep})}{dE^\mathrm{dep}} = A^\mathrm{eff}/(E^\mathrm{dep}_{i+1} - E^\mathrm{dep}_{i})$.  Since this process applies to the histograms generated for each primary energy $E^\mathrm{pri}$, the results can be seen as a function also of $E^\mathrm{pri}$: $\frac{dA^\mathrm{eff}(E^\mathrm{dep},E^\mathrm{pri})}{dE^\mathrm{dep}}$.

This function, determined at the $E^\mathrm{dep}$ bin centers and each $E^\mathrm{pri}$, approximates the true detector response function.  ... give examples ...  Ideally, the input spectrum would be convolved with this function to determine the detected count distribution.  However, the detector does not measure the count distribution, only a sampling from that distribution, binned according to the digitization process during data collection.  As such, what we need is not $\frac{dA^\mathrm{eff}(E^\mathrm{dep},E^\mathrm{pri})}{dE^\mathrm{dep}}$, but its integral over the output bins.  We also need to know $\frac{dA^\mathrm{eff}(E^\mathrm{dep},E^\mathrm{pri})}{dE^\mathrm{dep}}$ at all $E^\mathrm{pri}$, not just the $E^\mathrm{pri}$ used in the simulation, requiring some interpolation.  Constructing a true DRM from this function subsequently requires assumption of a functional form of input spectrum and integration over some set of $E^\mathrm{pri}$ bins.  This processing, from histogram to function to DRM, breaks down into smoothing of individual histograms, interpolation between histograms, convolution with interpolated histograms, and DRM generation, described as follows.



** Smoothing of single histograms
The simulation results, i.e. histograms such as those shown in Figure \ref{fig:sampleHistograms}, are binned with very fine resolution to preserve as much information as possible.  The bins are far to fine to be useful, however, with the counts in each bin subject to wild statistical fluctuation.  This requires some sort of rebinning or smoothing.  Rebinning blurs out spectral features like the 511 keV annihilation line, which we would like to preserve, and smoothing cannot accurately capture such sharp spectral features.  Fortunately, such spectral features are limited in number and appear at predictable locations.  The only features identifiable in the spectra are the full-energy peak($E^\mathrm{pri}$), the annihilation line (511 keV), and one- and two-escape peaks ($E^\mathrm{pri} - 511$ keV, $E^\mathrm{pri} - 2 \times 511$ keV).  There may or may not also be a contribution from a two-annihilation-photon line ($2\times 511$ keV), especially at high primary energies, so this is also included.  As such, the approach taken here is to smooth the histogram without the spectral lines to give an estimate of the continuum, storing their values separately.

The smoothing technique used is weighted loess smoothing.  The loess estimate of a function at a point is the value of a weighted quadratic regression fit to the neighbors of the point in question.  The weights are determined by the distance from the point in question and the size of the neighborhood here is taken to be the nearest 11 points.  This smoothing effectively dampens out the statistical fluctuations, but note that the resulting points are no longer statistically independent.  The result of this procedure is a smoothed estimate of the continuum portion of the histogram.

This background can then be subtracted from the counts in the bins containing spectral lines, giving an estimate of the number of counts in each line.  A combination of these peak estimates with the continuum estimate can be compared to the original histogram as shown in Figures \ref{fig:sampleInterpBG1} and \ref{fig:sampleInterpBG2}.  These continuum and spectral line estimates can then be built upon to estimate the overall detector response function.

#+CAPTION: Top panel: Energy deposition histogram for 3.16 MeV photons at normal incidence on the BGO detector (black), compared to its smoothed counterpart (blue).  The bottom panels show the results of subtracting the smoothed histogram from the original, both in absolute counts and in standard deviations.
#+LABEL: fig:sampleInterpBG1
[[./sampleInterpBG.pdf]]

#+CAPTION: Top panel: Energy deposition histogram for 0.32 MeV photons at normal incidence on the BGO detector (black), compared to its smoothed counterpart (blue).  The bottom panels show the results of subtracting the smoothed histogram from the original, both in absolute counts and in standard deviations.
#+LABEL: fig:sampleInterpBG2
[[./sampleInterpBG2.pdf]]


** Interpolation between histograms
The smoothed single histograms described above only capture the response of the detector to a single primary energy.  Multiple smoothed histograms must be interpolated to determine the response at an arbitrary energy between those simulated.  This interpolation must include both interpolation of the continuum and of the spectral lines.

The continuum interpolation cannot be done with a typical bilinear method, since bilinear interpolation cannot capture a sharp cutoff that is not aligned to the grid such as the requirement that the maximum energy that can be deposited is the energy of the primary.  As such, the interpolation scheme used here is a weighted average of the two histograms with their energy deposition axes scaled such that the full energy peaks align.  More mathematically, if $f_1(E^\mathrm{dep})$ and $f_2(E^\mathrm{dep})$ are the smoothed estimates of the continuum for two nearby primary energies $E_1^\mathrm{pri}$ and $E_2^\mathrm{pri}$, the estimate of the continuum at an intermediate energy $E^\mathrm{pri}$ is
\begin{equation}
f(E^\mathrm{dep}) = f_1(\frac{E^\mathrm{dep} E_1^\mathrm{pri}}{E^\mathrm{pri}}) \frac{E_2^\mathrm{pri}-E^\mathrm{pri}}{E_2^\mathrm{pri}-E_1^\mathrm{pri}} + f_2(\frac{E^\mathrm{dep} E_2^\mathrm{pri}}{E^\mathrm{pri}}) \frac{E^\mathrm{pri}-E_1^\mathrm{pri}}{E_2^\mathrm{pri}-E_1^\mathrm{pri}}
\end{equation}
This essentially interpolates between the two continua along lines radiating out from the origin.

The counts in spectral lines can simply be linearly interpolated.

This interpolation can be tested by interpolating from to the histogram for a known $E^\mathrm{pri}$ from the histograms from flanking values of $E^\mathrm{pri}$.  A sample is shown in Figure \ref{fig:sampleInterpTest}.  Though there may seem to be some systematic offsets near full energy, the significance of those offsets is minimal as seen in the bottom panel, and note also that in the actual DRM calculations, the interpolation will be only between neigboring $E^\mathrm{pri}$, not over the longer interval in the figure as was done solely for confirmation of the interpolation technique.

#+CAPTION: Top panel: Energy deposition histogram for 3.98 MeV photons at normal incidence on the BGO detector (black), compared to an interpolation to the histogram for 3.98 MeV photons based on histograms for 3.16 MeV and 5.01 MeV primary photons (blue).  The bottom panels show the results of subtracting the interpolated histogram from the original, both in absolute counts and in standard deviations.
#+LABEL: fig:sampleInterpTest
[[./sampleInterpTest.pdf]]

There are some small errors for primaries with energies just above 1 MeV due to linear interpolation of annihilation and escape peaks which appear at slightly different rates in the simulation as in the interpolation, but these errors are not washed out in later stages and can be easily be removed if desired.


** Convolution with input spectrum form
The smoothing and interpolation described above all acted on the energy deposition histograms derived from simulations.  Construction of a DRM requires integration over bins, both in energy deposition and in primary energy.

As mentioned initially, a DRM is a matrix that converts from an input particle spectrum to a measured counts spectrum.  Writing a vector to represent a spectrum either requries some assumption about the interpolation between points or it implies some binning of the spectrum.  Interpolation is typically not used as a detector response matrix cannot be written due to interdependence of elements for reasonable interpolation schemes.  Binning, on the other hand, requries some assumption of the shape of the primary spectrum within a bin: if one of the numbers in the vector is 10, does that imply 10 primaries uniformly distributed over the bin, or exponentially, or logarithmically, or something else?  This is especially important at high energies, where logarithmic bins get very large and the differences between uniform, linear, exponential, and power law spectra are large.

As such, construction of a DRM requires convolution of a primary spectrum with the functions described above.  This convolution can be constructed from the smoothing and interpolations described above.  There is some subtlety related to the difference between continuum and the spectral line representations, however.

Convolution with the continuum is relatively straightforward and is done over a grid in primary energy over the range of interest.  Here the convolution of the primary spectrum with the continuum part of the detector response is simply the sum of the interpolated continua produced by primaries of each primary energy in the grid over the range of interest, weighted by the spectrum and the width of the the primary energy bin.  This sum is then normalized over the sum of all the weights used, converting it to a weighted average.

Contributions to the convolution from spectral lines are slightly more complicated.  Since spectral lines are arguably delta functions, spectral lines whose positions depend on the primary energy contribute to a particular energy deposition bin by an amount proportional both to the width of the energy deposition bin and to the primary spectrum at the primary energy necessary to put the line in the given energy deposition bin.  This calculation has to be done over the entire energy deposition histogram, not simply over the range of primary energies of interest, since the bin sizes are unequal and a grid at full energy will not produce proper spacing at the two-escape peak, for example.  Again, these calculations need to be normalized by dividing by the sum of all the weights used to give a weighted average consistent with the continuum contribution.

Stationary spectral lines (annihilation and $2\times$-annihilation lines) contribute counts given by the weighted average of their interpolated contributions.

Sample convolution outputs are shown in Figure \ref{fig:sampleConvolutions}.
   
#+CAPTION: Sample convolution of two input spectra with detector response interpolations.  The two input spectra are taken to be only nonzero for 3.6 MeV $< E^\mathrm{pri} <$ 4 MeV, with one $\propto 1/E^\mathrm{pri}^3$ and $\propto E^\mathrm{pri}^3$ as labeled.
#+LABEL: fig:sampleConvolutions
[[./sampleConv.pdf]]

** DRM generation
Given convolution of a given primary spectrum with the interpolated detector response, construction of a DRM requries repeated calculation of that convolution over the required primary energy bins.  The resulting detector response may not have the desired energy deposition bins, requiring rebinning by summing such that the counts are properly distributed over the desired bins.  

The final conversion that must be made is to normalize the matrix.  All of the manipulations described above act on histograms of observed counts, as the histograms are more smooth and their statistics are more easily understood than for representations of functions describing effective area per energy deposited.  As such, the matrices must be normalized in the same manner as histograms, i.e. by dividing by the total number of primaries simulated and multiplying by the area illuminated by the primaries.  This gives the DRM as measured in effective area, i.e. cm$^2$.  An image plot of a sample square DRM produced is shown in Figure \ref{fig:sampleDRM}.

#+CAPTION: Sample DRM as calculated for normal incidence photons on the BGO detector with a $1/E^\mathrm{pri}$ spectrum.  The color indicates the effective area for counts in the given deposited energy bin for primaries in the given primary energy bin in cm$^2$.  Scanning across the plot at a particular primary energy gives the shape of the deposited energy spectrum for the given primary energy.
#+LABEL: fig:sampleDRM
[[./sampleDRM.pdf]]

All of the analysis described above can be repeated for each simulated primary particle direction.  If desired, interpolation in direction can be made with the DRM matrix entries.

** Error analysis
Given the complexity of the above analysis, it is not particularly easy to estimate the statistical errors present in the final convolved DRM.  However, multiple simulations with the same parameters can be passed through the same processing steps and compared.  Figure \ref{fig:drmDiff} shows the standard deviation of the DRMs from a set of 5 simulations cm$^2$, and Figure \ref{fig:drmDiffPercent} shows the standard deviation divided by the mean in percentage.  The largest percent errors are $\sim 10$ %, but these occur in regions where the effective area is small.  These results seem therefore to be quite accurate, typically to within 3%.

#+CAPTION: Standard deviation of DRM elements over 7 identical simulations.  This is a representation of the statistical error in a single DRM, here executed with $5\times 10^5$ primary particles per primary energy.
#+LABEL: fig:drmDiff
[[./drmStdDev.pdf]]

#+CAPTION: Like Figure \ref{fig:drmDiff}, but showing standard deviation over mean of DRM elements, expressed as a percent.  This is a representation of the statistical error in a single DRM relative to the DRM itself.
#+LABEL: fig:drmDiffPercent
[[./drmPercErr.pdf]]

** Technical details
The manipulations and processing described above are written in R, a language typically used for statistical computing and visualization.  The file procDRM.r includes functions to read the output from GEANT, smooth histograms, interpolate between smoothed histograms, convolve spectra with detector response, and make plots.  The file is heavily commented and should be self-explanatory given the above description.

* DRM format/usage
\label{sect:DRMuse}
A detector response matrix as simulated, smoothed, interpolated, convolved, and normalized as described above, is thankfully straightforward to use.  The DRM in question has associated $E^\mathrm{pri}$ and $E^\mathrm{dep}$ bins.  The desired primary spectrum is integrated over $E^\mathrm{pri}$ bins, giving a vector of fluence in each primary energy bin (counts per area in each bin).  The DRM (in cm$^2$) is then multiplied by this vector, giving the predicted counts in each $E^\mathrm{dep}$ bin.  These deposited energy counts can be directly compared to the measured counts.


** subsection
#+begin_src R :session s1 :results output graphics :file 03_03_2012_calibration/spectra.png :width 800 :height 480 :exports both
# code goes here.
#+end_src

